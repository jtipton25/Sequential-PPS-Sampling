bias[N] <- 0
return(bias)
}
}
make.prob(N)
make.prob.perm(N) - 1:N/N
factorial(N - 2) / factorial(N) *sum(1:(N-1) * 1:(N-1) / (2:N))
make.prob <- function(N){
if(floor(N) < N){
"N must be an integer"
} else if(N < 2){
"N must be greater than 2"
} else if(N == 2){
bias <- c(1 / 4, 0)
} else {
bias <- vector(length = N)
for(j in 1:(N-1)){
bias[j] <- factorial(N - 2) / factorial(N) * sum(1:(N-1) * 1:(N-1) / (2:N)) #* (N - j)
}
bias[N] <- 0
return(bias)
}
}
N <- 4
make.prob(N)
make.prob.perm(N) - 1:N/N
N <- 3
make.prob(N)
make.prob.perm(N) - 1:N/N
.30555555/.13888889
as.fractions(sum(1:(N-1) * 1:(N-1) / (2:N)))
as.fractions(1:(N-1) * 1:(N-1) / (2:N))
N <- 6
factorial(N - 2) / factorial(N) * sum(1:(N-1) * 1:(N-1) / (2:N))
as.fractions(1:(N-1) * 1:(N-1) / (2:N))
factorial(N - 2)
make.prob <- function(N){
if(floor(N) < N){
"N must be an integer"
} else if(N < 2){
"N must be greater than 2"
} else if(N == 2){
bias <- c(1 / 4, 0)
} else {
bias <- vector(length = N)
for(j in 1:(N-1)){
bias[j] <- factorial(N - 2) / factorial(N) * (sum(1:(N-1) * 1:(N-1) / (2:N)) + 1 /2) #* (N - j)
}
bias[N] <- 0
return(bias)
}
}
## Works for N=1:4, breaks down for N=5 and 6
N <- 6
make.prob(N)
make.prob.perm(N) - 1:N/N
make.prob(N)
make.prob.perm(N)
N <- 4
make.prob(N)
make.prob.perm(N)
make.prob <- function(N){
if(floor(N) < N){
"N must be an integer"
} else if(N < 2){
"N must be greater than 2"
} else if(N == 2){
bias <- c(1 / 4, 0)
} else {
bias <- vector(length = N)
for(j in 1:(N-1)){
bias[j] <- factorial(N - 2) / factorial(N) * (sum(1:(N-1) * 1:(N-1) / (2:N))) + 1 /2 #* (N - j)
}
bias[N] <- 0
return(bias)
}
}
## Works for N=1:4, breaks down for N=5 and 6
N <- 4
make.prob(N)
make.prob.perm(N)
make.prob <- function(N){
if(floor(N) < N){
"N must be an integer"
} else if(N < 2){
"N must be greater than 2"
} else if(N == 2){
bias <- c(1 / 4, 0)
} else {
bias <- vector(length = N)
for(j in 1:(N-1)){
#bias[j] <- (factorial(N - 2) / factorial(N) * (sum(1:(N-1) * 1:(N-1) / (2:N))) + 1 /2) #* (N - j)
bias[j] <- (factorial(N - 2) / factorial(N) * (sum(1:(N-1) * 1:(N-1) / (2:N))) + 1 /2 - (N - 1) / N) #* (N - j)
}
bias[N] <- 0
return(bias)
}
}
N <- 4
make.prob(N)
make.prob.perm(N)
make.prob <- function(N){
if(floor(N) < N){
"N must be an integer"
} else if(N < 2){
"N must be greater than 2"
} else if(N == 2){
bias <- c(1 / 4, 0)
} else {
bias <- vector(length = N)
for(j in 1:(N-1)){
#bias[j] <- (factorial(N - 2) / factorial(N) * (sum(1:(N-1) * 1:(N-1) / (2:N))) + 1 /2) #* (N - j)
bias[j] <- (factorial(N - 2) / factorial(N) * (sum(1:(N-1) * 1:(N-1) / (2:N))) + 1 /2 - (N - 1) / N) * (N - j)
}
bias[N] <- 0
return(bias)
}
}
make.prob.perm(N) - 1:N / N
make.prob(N)
N <- 5
make.prob(N)
make.prob.perm(N) - 1:N / N
N <- 6
make.prob(N)
make.prob.perm(N) - 1:N / N
N <- 7
make.prob(N)
make.prob.perm(N) - 1:N / N
N <- 8
make.prob(N)
make.prob.perm(N) - 1:N / N
N <- 9
make.prob(N)
make.prob.perm(N) - 1:N / N
N <- 10
make.prob(N)
make.prob.perm(N) - 1:N / N
N <- 100
make.prob(N)
N <- 10000
## Works fast
make.prob(N)
warnings()
N <- 1000
make.prob(N)
?factorial
make.prob <- function(N){
if(floor(N) < N){
"N must be an integer"
} else if(N < 2){
"N must be greater than 2"
} else if(N == 2){
bias <- c(1 / 4, 0)
} else {
bias <- vector(length = N)
for(j in 1:(N-1)){
#bias[j] <- (factorial(N - 2) / factorial(N) * (sum(1:(N-1) * 1:(N-1) / (2:N))) + 1 /2) #* (N - j)
#bias[j] <- (factorial(N - 2) / factorial(N) * (sum(1:(N-1) * 1:(N-1) / (2:N))) + 1 /2 - (N - 1) / N) * (N - j)
bias[j] <- (1 / (N * (N - 1)) * (sum(1:(N-1) * 1:(N-1) / (2:N))) + 1 /2 - (N - 1) / N) * (N - j)
}
bias[N] <- 0
return(bias)
}
}
N <- 1000
make.prob(N)
N <- 6
## Works fast
make.prob(N)
## Works slow
make.prob.perm(N) - 1:N / N
N <- 7
## Works fast
make.prob(N)
## Works slow
make.prob.perm(N) - 1:N / N
sum(factorial(N - 2) * (1:(N-1)) / (2:N) * 1:(N-1) + factorial (N - 2)) / factorial(N)
N <- 700000
## Works fast
make.prob(N)
N <- 7000
## Works fast
make.prob(N) + 1:N / N
N <- 7
## Works fast
make.prob(N) + 1:N / N
## Works slow
make.prob.perm(N) - 1:N / N
sum(factorial(N - 2) * (1:(N-1)) / (2:N) * 1:(N-1) + factorial (N - 2)) / factorial(N)
make.prob.perm(N)
make.prob(N) + 1:N / N
library(permute)
library(MASS)
##
## Exact Simulation of sampling design
##
ctrl <- how(maxperm = 10000000)
N <- 4
make.prob.perm <- function(N){
perm.mat <- rbind(1:N, allPerms(N, control = ctrl))
pi <- matrix(nrow = dim(perm.mat)[1], ncol = dim(perm.mat)[2])
for(i in 1:dim(perm.mat)[1]){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
#	pi[i,] <- pi[i, ][perm.mat[i,]]
}
apply(pi, 2, mean)
}
##
## Analytic Formula for sampling weights
##
##
## \hat{\pi}_i - \pi_i  = (\frac{(N - 2)!} {N!} * \sum_{k = 1}^{N - 1} k \frac{k} {k + 1} + \frac{1} {2} - \frac{N - 1} {N}) * (N - i)
##
make.prob <- function(N){
if(floor(N) < N){
"N must be an integer"
} else if(N < 2){
"N must be greater than 2"
} else if(N == 2){
bias <- c(1 / 4, 0)
} else {
bias <- vector(length = N)
for(j in 1:(N-1)){
#bias[j] <- (factorial(N - 2) / factorial(N) * (sum(1:(N-1) * 1:(N-1) / (2:N))) + 1 /2) #* (N - j)
#bias[j] <- (factorial(N - 2) / factorial(N) * (sum(1:(N-1) * 1:(N-1) / (2:N))) + 1 /2 - (N - 1) / N) * (N - j)
bias[j] <- (1 / (N * (N - 1)) * (sum(1:(N-1) * 1:(N-1) / (2:N))) + 1 /2 - (N - 1) / N) * (N - j)
}
bias[N] <- 0
return(bias)
}
}
## Works for N=1:8 relatively quick, slows down dramatically for N > 8
N <- 7
## Works fast
make.prob(N) + 1:N / N
## Works slow
make.prob.perm(N)
make.gamma.mixture <- function(N, alpha, beta){
# makes a mixture of gamma distributions given alpha and beta vectors
n <- length(alpha)
samp <- sample(1:n, N, replace = TRUE)
dbh <- rgamma(N, alpha[samp], beta[samp])
}
make.sim.biomass <- function(dbh, b0, b1, s2){
# make a power law distribution function with exponential random normal error and restricts values less than 0
N <- length(dbh)
bio <- b0 * dbh ^ b1 * exp(rnorm(N, 0, s2))
bio[bio < 0] <- min(bio)
if(length(bio[bio < 0]) == 0){
return(bio)
} else{
return(bio)
"some values of biomass were less than 0 so were set to min(bio)"
}
}
make.model.plot <- function(dbh, bio, file = 'pathname'){ # plot model fits and save to file using file = 'pathname'
if(file != 'pathname'){
pdf(file = "fullModel")
}
N <- length(dbh)
layout(matrix(1:4, nrow = 2))
hist(dbh, breaks = floor(N / 10))
hist(bio, breaks = floor(N / 10))
# model
model <- lm(log(bio) ~ log(dbh))
newdbh <- seq(min(dbh), max(dbh), length.out = N)
preds <- predict(model, newdata = data.frame(dbh = newdbh), interval = "predict")
plot(bio ~ dbh)
curve(exp(model$coeff[1]) * x^model$coeff[2], add = TRUE)
polygon(c(rev(newdbh), newdbh), c(rev(exp(preds[, 3])), exp(preds[, 2])), col = adjustcolor('grey80', alpha.f=0.5), border = NA)
lines(newdbh, exp(preds[ ,3]), lty = 'dashed', col = 'red')
lines(newdbh, exp(preds[ ,2]), lty = 'dashed', col = 'red')
plot(log(bio) ~ log(dbh), main = 'log scale')
abline(model)
polygon(c(rev(log(newdbh)), log(newdbh)), c(rev(preds[, 3]), preds[, 2]), col = adjustcolor('grey80', alpha.f=0.5), border = NA)
lines(log(newdbh), preds[ ,3], lty = 'dashed', col = 'red')
lines(log(newdbh), preds[ ,2], lty = 'dashed', col = 'red')
if(file != 'pathname'){
dev.off()
}
}
make.pi <- function(N){
if(floor(N) < N){
"N must be an integer"
} else if(N < 2){
"N must be greater than 2"
} else if(N == 2){
bias <- c(1 / 4, 0)
} else {
bias <- vector(length = N)
for(j in 1:(N-1)){
bias[j] <- (1 / (N * (N - 1)) * (sum(1:(N-1) * 1:(N-1) / (2:N))) + 1 /2 - (N - 1) / N) * (N - j)
}
bias[N] <- 0
return(bias + 1:N / N)
}
}
make.samp <- function(dbh, bio, n, method = 'srs'){
N <- length(dbh)
if(method == 'srs'){
p <- n * rep(1 / N, N)
samp <- sample(1:N, n, prob = p)
}
if(method == 'pps'){
p <- n * dbh / sum(dbh)
samp <- sample(1:N, n, prob = p)
}
if(method == 'ecdf'){
p <- 2 * n / N * ecdf(dbh)(dbh)
samp <- which(rbinom(1:N, 1, p) == 1)
}
if(method == 'design'){
idx <- sample(1:N)
p <- vector(length = N)
for(k in 1:N){
x <- dbh[idx[1:k]]
fn <- ecdf(x)
p[k] <- fn(x)[k]
}
p <- p * 2 * n / N # potential sample size adjustment
samp <- which(rbinom(N, 1, p) == 1)
idx <- order(dbh)
p <- make.pi(N)
}
prob <- p[samp]
dbh.samp <- dbh[samp]
dbh.mn <- 1 / N * sum(dbh.samp / prob)
bio.samp <- bio[samp]
bio.mn <- 1 / N * sum(bio.samp / prob)
list(dbh = dbh.samp, dbh.mn = dbh.mn, bio = bio.samp, bio.mn = bio.mn, p = p, samp = samp)
}
make.bias.est <- function(iter, dbh, bio, n, method = 'srs'){ # estimate bias in regression coefficients from sampling design
out <- make.samp(dbh, bio, n, method)
model <- lm(log(bio) ~ log(dbh), data = data.frame(dbh = out$dbh, bio = out$bio))
#model.wt <- lm(log(bio) ~ log(dbh), weights = out$p[out$samp], data = data.frame(dbh = out$dbh, bio = out$bio))
model.wt <- lm(log(bio) ~ log(dbh), weights = 1 / out$p[out$samp], data = data.frame(dbh = out$dbh, bio = out$bio))
newdata <- data.frame(dbh = dbh[ - out$samp])
preds <- predict(model, newdata = newdata)
preds.wt <- predict(model.wt, newdata = newdata)
pred.mse <- mean((exp(preds) - bio[ - out$samp])^2)
pred.wt.mse <- mean((exp(preds.wt) - bio[ - out$samp])^2)
#c(summary(model)$coef[, 1], summary(model)$coef[, 2], summary(model.wt)$coef[, 1], summary(model.wt)$coef[, 2], pred.mse, pred.wt.mse)
bias <- c(summary(model)$coef[, 1], summary(model)$coef[, 2], summary(model.wt)$coef[, 1], summary(model.wt)$coef[, 2], pred.mse, pred.wt.mse)
names(bias) <- c('EST intercept OLS', 'EST slope OLS', 'SE intercept OLS', 'SE slope OLS', 'EST intercept WLS', 'EST slope WLS', 'SE intercept WLS', 'SE slope WLS', 'MSPE OLS', 'MSPE WLS')
return(bias)
}
##
## Simulate dbh
##
N <- 1000 # finite population size
n <- 100 # expected sample size
##
## Start with a population that is a mixture of Gamma Distributions
##
alpha <- c(2, 4, 6, 8) # gamma mixture parameter
beta <- c(12, 10, 8, 6) # gamma mixture parameter
dbh <- make.gamma.mixture(N, alpha, beta)
##
## Plot DBH
##
layout(matrix(1:4, 2, 2))
for(i in 1:4){ # plot the four distibutions to mix
curve(dgamma(x, alpha[i], beta[i]), from = 0, to = 4)
}
par(mfrow = c(1, 1))
#pdf(file = 'dbh1.pdf')
hist(dbh, breaks = 20)
#dev.off()
##
## True mean and variance for DBH
##
dbh.mn <- mean(dbh)
dbh.var <- var(dbh)
##
## Simulate Biomass
##
b0 <- 5
b1 <- 2
s2 <- 1/4
bio <- make.sim.biomass(dbh, b0, b1, s2)
bio.mn <- mean(bio)
bio.var <- var(bio)
##
## Plot Data
##
#make.model.plot(dbh, bio, file = "fullModel.pdf")
make.model.plot(dbh, bio)
##
## SRS sampling
##
out.srs <- make.samp(dbh, bio, n, method = 'srs')
dbh.mn - out.srs$dbh.mn
bio.mn - out.srs$bio.mn
##
## Plot relationship for SRS sample
##
make.model.plot(out.srs$dbh, out.srs$bio)
##
## Estimate Bias from SRS sampling
##
bias.srs <- sapply(1:1000, make.bias.est, dbh = dbh, bio = bio, n = 100, method = 'srs')
idx.mn <- c(1:2, 5:6)
idx.var <- c(3:4, 7:8)
idx.mspe <- 9:10
apply(bias.srs[idx.mn,], 1, mean) - rep(c(log(b0), b1), 2) # seems to be unbiasedly estimating the regression parameters
## variance of the means - mean of the variances
apply(bias.srs[idx.mn, ], 1, var) - apply(bias.srs[idx.var, ], 1, mean) # variance of estimator vs estimated variance for regression parameters seems to be unbiased
# mean MSPE
apply(bias.srs[idx.mspe, ], 1, mean)
##
## True PPS sampling design
##
#out.pps <- make.pps.samp(dbh, bio, n)
out.pps <- make.samp(dbh, bio, n, method = 'pps')
dbh.mn - out.pps$dbh.mn
bio.mn - out.pps$bio.mn
##
## Plot relationship for PPS sample
##
make.model.plot(out.pps$dbh, out.pps$bio)
##
## Estimate Bias from pps sampling
##
bias.pps <- sapply(1:1000, make.bias.est, dbh = dbh, bio = bio, n = 100, method = 'pps')
apply(bias.pps[idx.mn,], 1, mean) - rep(c(log(b0), b1), 2) # seems to be unbiasedly estimating the regression parameters
## variance of the means - mean of the variances
apply(bias.pps[idx.mn, ], 1, var) - apply(bias.pps[idx.var, ], 1, mean) # variance of estimator vs estimated variance for regression parameters seems to be unbiased
# mean MSPE
apply(bias.pps[idx.mspe, ], 1, mean)
##
## ecdf sampling design
##
#out.ecdf <- make.ecdf.samp(dbh, bio, n)
out.ecdf <- make.samp(dbh, bio, n, method = "ecdf")
dbh.mn - out.ecdf$dbh.mn
bio.mn - out.ecdf$bio.mn
##
## Plot relationship for ecdf sample
##
make.model.plot(out.ecdf$dbh, out.ecdf$bio)
##
## Estimate Bias from ecdf sampling
##
bias.ecdf <- sapply(1:1000, make.bias.est, dbh = dbh, bio = bio, n = 100, method = 'ecdf')
apply(bias.ecdf[idx.mn,], 1, mean) - rep(c(log(b0), b1), 2) # seems to be unbiasedly estimating the regression parameters
## variance of the means - mean of the variances
apply(bias.ecdf[idx.mn, ], 1, var) - apply(bias.ecdf[idx.var, ], 1, mean) # variance of estimator vs estimated variance for regression parameters seems to be unbiased
# mean MSPE
apply(bias.ecdf[idx.mspe, ], 1, mean) # seems to be similar to pps (at least for this particular finite population)
##
## Sequential ecdf design
##
##
## Sample the first element (x1) with probability 1
## Sample the second element (x2) with probability 1 if x2 > x1
##                                                 1/2 if x2 <= x1
##
## Sample the third element (x3) with probability 1 if x3 > x1 & x2
##                                                2/3 if x3 > x1 & x3 < x2
##                                                2/3 if x3 > x2 & x3 < x1
##                                                1/3 if x3 < x1 & x2
##
## And so on
##
##
## Testing the behavior of the probability of being sampled pi_i for one population
##
#out.design <- make.design.samp(dbh, bio, n)
out.design <- make.samp(dbh, bio, n, method = "design")
make.model.plot(out.design$dbh, out.design$bio)
make.model.plot(dbh, bio)
bias.design <- sapply(1:100, make.bias.est, dbh = dbh, bio = bio, n = 100, method = 'design')
apply(bias.design[idx.mn,], 1, mean) - rep(c(log(b0), b1), 2) # seems to be unbiasedly estimating the regression parameters
## variance of the means - mean of the variances
apply(bias.design[idx.mn, ], 1, var) - apply(bias.design[idx.var, ], 1, mean) # variance of estimator vs estimated variance for regression parameters seems to be unbiased
# mean MSPE
apply(bias.design[idx.mspe, ], 1, mean) # seems to be similar to pps (at least for this particular finite population)
apply(bias.srs[idx.mspe, ], 1, mean)
apply(bias.pps[idx.mspe, ], 1, mean)
apply(bias.ecdf[idx.mspe, ], 1, mean)
apply(bias.design[idx.mspe, ], 1, mean)
N <- 100
W <- matrix(0, nrow = N, ncol = N)
W[1:(N - 1), 2:N]
W[1:(N - 1), 2:N]
str(W[1:(N - 1), 2:N])
c(1,2):c(N-1,N)
W[c(1:(N - 1), 2:N)]
W[c(1:(N - 1), 2:N)] <- 1
N <- 10 #population size
W <- matrix(0, nrow = N, ncol = N)
W[c(1:(N - 1), 2:N)] <- 1
W
W <- matrix(0, nrow = N, ncol = N)
W[c(1:(N - 1), 2:N)] <- 1
W <- matrix(0, nrow = N, ncol = N)
W[c(1:(N - 1), 2:N)] <- 1
W
c(1:(N - 1), 2:N)
cbind(1:(N - 1), 2:N)
W <- matrix(0, nrow = N, ncol = N)
W[cbind(1:(N - 1), 2:N)] <- 1
W
N <- 100 #population size
W <- matrix(0, nrow = N, ncol = N)
W[cbind(1:(N - 1), 2:N)] <- 1
W
