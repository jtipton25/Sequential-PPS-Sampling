hist(pi.save - 2 * n / N * cdffn(dbh), breaks = 20) # Not the same as pps sampling
cdffn(dbh)
sort(cdffn(dbh))
hist(pi.save - 2 * n / N * cdffn(dbh) - 1/N, breaks = 20) # Not the same as pps sampling
mean(pi.save - 2 * n / N * cdffn(dbh)- 1/N)
mean(pi.save - 2 * n / N * cdffn(dbh))
hist(pi.save - 2 * n / N * cdffn(dbh))
min(pi.save - 2 * n / N * cdffn(dbh))
max(pi.save - 2 * n / N * cdffn(dbh))
pi.save
cdffn(dbh)
pi.save - cdffn(dbh)
iter <- 1000
est.mn.dbh <- vector(length = iter)
est.var.dbh <- vector(length = iter)
est.mn.bio <- vector(length = iter)
est.var.bio <- vector(length = iter)
bio.fit <- vector(mode = 'list', length = iter)
bio.fit.weight <- vector(mode = 'list', length = iter)
bio.fit.srs <- vector(mode = 'list', length = iter)
pi.save <- rep(0, length = N)
n.save <- vector(length = iter)
s2.core <- 1/8 # Sampling error from coring tree
coefs <- matrix(nrow = iter, ncol = 2)
for(i in 1:iter){
if(i %% 100 == 0){
cat(i, ' ')
}
p <- vector(length = N)
samp.srs <- sample(1:N, n) #SRS sampling for comparison
samp <- sample(1:N)
dbh.samp <- dbh[samp]
bio.samp <- bio[samp]
for(k in 1:N){
x <- dbh.samp[1:k]
fn <- ecdf(x)
p[k] <- fn(x)[k]
}
#	p <- p * 2 * n / N #potential sample size adjustment
samples <- rbinom(N, 1, p)
dbh.pps <- dbh.samp[which(samples == 1)]
error <- rnorm(N, 0, s2.core)
bio.pps <- (bio.samp*exp(error))[which(samples == 1)] #exponential error due to measurement error sampling the cores, not sampling design
n.save[i] <- sum(samples)
probs <- p[which(samples == 1)]
p[samp] <- p
pi.save <- pi.save + 1 / iter * p
est.mn.dbh[i] <- 1 / N * sum(dbh.pps / probs) # check these
est.var.dbh[i] <- (1 / N) * var(dbh.pps / probs)
est.mn.bio[i] <- 1 / N * sum(bio.pps / probs) # check these
est.var.bio[i] <- (1 / N) * var(bio.pps / probs)
model.pps <- lm(log(bio.pps) ~ log(dbh.pps))
coefs[i, ] <- model.pps$coef
bio.fit[[i]] <- exp(model.pps$coef[1]) * dbh^model.pps$coef[2]
model.srs <- lm(log((bio*exp(error))[samp.srs]) ~ log(dbh[samp.srs]))
bio.fit.srs[[i]] <- exp(model.srs$coef[1]) * dbh^model.srs$coef[2]
model.pps.weight <- lm(log(bio.pps) ~ log(dbh.pps), weights = 1 / fn(dbh.pps))
bio.fit.weight[[i]] <- exp(model.pps.weight$coef[1]) * dbh^model.pps.weight$coef[2]
}
N <- 1000
n <- 100
#alpha <- 2
#beta <- 6
#curve(dgamma(x, alpha, beta))
#dbh <- rgamma(N, alpha, beta)
#dbh <- runif(N)
alpha <- c(2, 4, 6, 8)
beta <- c(12, 10, 8, 6)
layout(matrix(1:4, 2, 2))
for(i in 1:4){
curve(dgamma(x, alpha[i], beta[i]), from = 0, to = 4)
}
samp.density <- sample(1:4, N, replace = TRUE)
dbh <- 5 + 10 * rgamma(N, alpha[samp.density], beta[samp.density])
par(mfrow = c(1, 1))
hist(dbh, breaks = 20)
truth.dbh <- 1 / N * sum(dbh)
truth.dbh
N <- 1000
n <- 100
#alpha <- 2
#beta <- 6
#curve(dgamma(x, alpha, beta))
#dbh <- rgamma(N, alpha, beta)
#dbh <- runif(N)
alpha <- c(2, 4, 6, 8)
beta <- c(12, 10, 8, 6)
layout(matrix(1:4, 2, 2))
for(i in 1:4){
curve(dgamma(x, alpha[i], beta[i]), from = 0, to = 4)
}
samp.density <- sample(1:4, N, replace = TRUE)
dbh <- 5 + 10 * rgamma(N, alpha[samp.density], beta[samp.density])
par(mfrow = c(1, 1))
hist(dbh, breaks = 20)
truth.dbh <- 1 / N * sum(dbh)
truth.dbh
##
## Simulate Biomass
##
a <- 2
b <- 2
s2 <- 1 / 4
epsilon <- rnorm(N, 0, s2)
bio <- a * dbh ^ b * exp(epsilon)
bio[bio < 0]
plot(log(bio) ~ log(dbh))
model <- lm(log(bio) ~ log(dbh))
abline(model)
plot(resid(model) ~ fitted(model))
abline(h=0)
plot(bio ~ dbh)
curve(exp(model$coeff[1]) * x^model$coeff[2], add = TRUE)
truth.bio <- mean(bio)
##
## True PPS sampling design
##
p <- dbh / sum(dbh)
hist(p)
samp <- sample(1:N, n, prob = p)
estimate.dbh <- 1 / N * sum(1 / n * dbh[samp] / p[samp])
estimate.bio <- 1 / N * sum(1 / n * bio[samp] / p[samp])
truth.dbh - estimate.dbh
truth.bio - estimate.bio
##
## Compare True allometric relationship to pps allometric relationship
##
model.pps <- lm(log(bio[samp]) ~ log(dbh[samp]))
model
model.pps
layout(matrix(1:4, 2))
plot(log(bio) ~ log(dbh))
abline(model)
plot(bio ~ dbh)
curve(exp(model$coeff[1]) * x^model$coeff[2], add = TRUE)
plot(log(bio[samp]) ~ log(dbh[samp]))
abline(model.pps)
plot(bio[samp] ~ dbh[samp])
curve(exp(model.pps$coeff[1]) * x^model.pps$coeff[2], add = TRUE)
##
## Estimate Bias from pps sampling
##
iter <- 100
coefs <- matrix(nrow = iter, ncol = 2)
for(j in 1:iter){
samp <-  sample(1:N, n, prob = p)
model.pps <- lm(log(bio[samp]) ~ log(dbh[samp]))
coefs[j, ] <- model.pps$coef
}
apply(coefs, 2, mean)
c(log(a), b)
## Seems to be unbiasedly estimating the regression parameters
##
## Sequential PPS design
##
##
## Sample the first element (x1) with probability 1
## Sample the second element (x2) with probability 1 if x2 > x1
##                                                 1/2 if x2 <= x1
##
## Sample the third element (x3) with probability 1 if x3 > x1 & x2
##                                                2/3 if x3 > x1 & x3 < x2
##                                                2/3 if x3 > x2 & x3 < x1
##                                                1/3 if x3 < x1 & x2
##
## And so on
##
##
## Testing the behavior of the probability of being sampled pi_i for one population
##
#dbh <- runif(N)
#alpha <- 2
#beta <- 6
hist(dbh, freq = FALSE, breaks = 20)
#curve(dgamma(x, alpha, beta))
iter <- 1000
est.mn.dbh <- vector(length = iter)
est.var.dbh <- vector(length = iter)
est.mn.bio <- vector(length = iter)
est.var.bio <- vector(length = iter)
bio.fit <- vector(mode = 'list', length = iter)
bio.fit.weight <- vector(mode = 'list', length = iter)
bio.fit.srs <- vector(mode = 'list', length = iter)
pi.save <- rep(0, length = N)
n.save <- vector(length = iter)
s2.core <- 1/8 # Sampling error from coring tree
coefs <- matrix(nrow = iter, ncol = 2)
for(i in 1:iter){
if(i %% 100 == 0){
cat(i, ' ')
}
p <- vector(length = N)
samp.srs <- sample(1:N, n) #SRS sampling for comparison
samp <- sample(1:N)
dbh.samp <- dbh[samp]
bio.samp <- bio[samp]
for(k in 1:N){
x <- dbh.samp[1:k]
fn <- ecdf(x)
p[k] <- fn(x)[k]
}
#	p <- p * 2 * n / N #potential sample size adjustment
samples <- rbinom(N, 1, p)
dbh.pps <- dbh.samp[which(samples == 1)]
error <- rnorm(N, 0, s2.core)
bio.pps <- (bio.samp*exp(error))[which(samples == 1)] #exponential error due to measurement error sampling the cores, not sampling design
n.save[i] <- sum(samples)
probs <- p[which(samples == 1)]
p[samp] <- p
pi.save <- pi.save + 1 / iter * p
est.mn.dbh[i] <- 1 / N * sum(dbh.pps / probs) # check these
est.var.dbh[i] <- (1 / N) * var(dbh.pps / probs)
est.mn.bio[i] <- 1 / N * sum(bio.pps / probs) # check these
est.var.bio[i] <- (1 / N) * var(bio.pps / probs)
model.pps <- lm(log(bio.pps) ~ log(dbh.pps))
coefs[i, ] <- model.pps$coef
bio.fit[[i]] <- exp(model.pps$coef[1]) * dbh^model.pps$coef[2]
model.srs <- lm(log((bio*exp(error))[samp.srs]) ~ log(dbh[samp.srs]))
bio.fit.srs[[i]] <- exp(model.srs$coef[1]) * dbh^model.srs$coef[2]
model.pps.weight <- lm(log(bio.pps) ~ log(dbh.pps), weights = 1 / fn(dbh.pps))
bio.fit.weight[[i]] <- exp(model.pps.weight$coef[1]) * dbh^model.pps.weight$coef[2]
}
for(i in 1:iter){
if(i %% 100 == 0){
cat(i, ' ')
}
p <- vector(length = N)
samp.srs <- sample(1:N, n) #SRS sampling for comparison
samp <- sample(1:N)
dbh.samp <- dbh[samp]
bio.samp <- bio[samp]
for(k in 1:N){
x <- dbh.samp[1:k]
fn <- ecdf(x)
p[k] <- fn(x)[k]
}
#	p <- p * 2 * n / N #potential sample size adjustment
samples <- rbinom(N, 1, p)
dbh.pps <- dbh.samp[which(samples == 1)]
error <- rnorm(N, 0, s2.core)
bio.pps <- (bio.samp*exp(error))[which(samples == 1)] #exponential error due to measurement error sampling the cores, not sampling design
n.save[i] <- sum(samples)
probs <- p[which(samples == 1)]
p[samp] <- p
pi.save <- pi.save + 1 / iter * p
est.mn.dbh[i] <- 1 / N * sum(dbh.pps / probs) # check these
est.var.dbh[i] <- (1 / N) * var(dbh.pps / probs)
est.mn.bio[i] <- 1 / N * sum(bio.pps / probs) # check these
est.var.bio[i] <- (1 / N) * var(bio.pps / probs)
model.pps <- lm(log(bio.pps) ~ log(dbh.pps))
coefs[i, ] <- model.pps$coef
bio.fit[[i]] <- exp(model.pps$coef[1]) * dbh^model.pps$coef[2]
model.srs <- lm(log((bio*exp(error))[samp.srs]) ~ log(dbh[samp.srs]))
bio.fit.srs[[i]] <- exp(model.srs$coef[1]) * dbh^model.srs$coef[2]
model.pps.weight <- lm(log(bio.pps) ~ log(dbh.pps), weights = 1 / fn(dbh.pps))
bio.fit.weight[[i]] <- exp(model.pps.weight$coef[1]) * dbh^model.pps.weight$coef[2]
}
cdffn <- ecdf(dbh)
hist(pis.save)
hist(pi.save)
layout(c(1,1))
hist(pi.save)
hist(pi.save - 1/N)
hist(pi.save - 1 - 1/N)
hist(pi.save - 1/2 - 1/N)
hist(pi.save - 1/2)
hist(pi.save - cfffn(dbh))
hist(pi.save - cdffn(dbh))
hist(pi.save - cdffn(dbh)); abline(v = 0)
hist(pi.save - cdffn(dbh)); abline(v = 0, lty = 2)
hist(pi.save - cdffn(dbh)); abline(v = 0, lwd = 2)
hist(pi.save - cdffn(dbh)); abline(v = 0, lwd = 4)
hist(pi.save - cdffn(dbh)); abline(v = 0, lwd = 8)
hist(pi.save - 1/2 * cdffn(dbh)); abline(v = 0, lwd = 8)
hist(pi.save - cdffn(dbh)); abline(v = 0, lwd = 8)
hist(pi.save - cdffn(dbh) - 1/N); abline(v = 0, lwd = 8)
hist(pi.save - cdffn(dbh) - n/N); abline(v = 0, lwd = 8)
hist(pi.save - cdffn(dbh) - 1/N); abline(v = 0, lwd = 8)
hist(pi.save - cdffn(dbh) - 10/N); abline(v = 0, lwd = 8)
hist(pi.save - cdffn(dbh) - 3/N); abline(v = 0, lwd = 8)
hist(pi.save - cdffn(dbh) - 1/N); abline(v = 0, lwd = 8)
N
hist(pi.save - cdffn(dbh)); abline(v = 0, lwd = 8)
min(pi.save - cdffn(dbh))
max(pi.save - cdffn(dbh))
10/N
1/N
iter <- 10000
est.mn.dbh <- vector(length = iter)
est.var.dbh <- vector(length = iter)
est.mn.bio <- vector(length = iter)
est.var.bio <- vector(length = iter)
bio.fit <- vector(mode = 'list', length = iter)
bio.fit.weight <- vector(mode = 'list', length = iter)
bio.fit.srs <- vector(mode = 'list', length = iter)
pi.save <- rep(0, length = N)
n.save <- vector(length = iter)
s2.core <- 1/8 # Sampling error from coring tree
coefs <- matrix(nrow = iter, ncol = 2)
est.mn.dbh <- vector(length = iter)
est.var.dbh <- vector(length = iter)
est.mn.bio <- vector(length = iter)
est.var.bio <- vector(length = iter)
bio.fit <- vector(mode = 'list', length = iter)
bio.fit.weight <- vector(mode = 'list', length = iter)
bio.fit.srs <- vector(mode = 'list', length = iter)
pi.save <- rep(0, length = N)
n.save <- vector(length = iter)
s2.core <- 1/8 # Sampling error from coring tree
coefs <- matrix(nrow = iter, ncol = 2)
iter <- 10000
est.mn.dbh <- vector(length = iter)
est.var.dbh <- vector(length = iter)
est.mn.bio <- vector(length = iter)
est.var.bio <- vector(length = iter)
bio.fit <- vector(mode = 'list', length = iter)
bio.fit.weight <- vector(mode = 'list', length = iter)
bio.fit.srs <- vector(mode = 'list', length = iter)
pi.save <- rep(0, length = N)
n.save <- vector(length = iter)
s2.core <- 1/8 # Sampling error from coring tree
coefs <- matrix(nrow = iter, ncol = 2)
for(i in 1:iter){
if(i %% 100 == 0){
cat(i, ' ')
}
p <- vector(length = N)
samp.srs <- sample(1:N, n) #SRS sampling for comparison
samp <- sample(1:N)
dbh.samp <- dbh[samp]
bio.samp <- bio[samp]
for(k in 1:N){
x <- dbh.samp[1:k]
fn <- ecdf(x)
p[k] <- fn(x)[k]
}
#	p <- p * 2 * n / N #potential sample size adjustment
samples <- rbinom(N, 1, p)
dbh.pps <- dbh.samp[which(samples == 1)]
error <- rnorm(N, 0, s2.core)
bio.pps <- (bio.samp*exp(error))[which(samples == 1)] #exponential error due to measurement error sampling the cores, not sampling design
n.save[i] <- sum(samples)
probs <- p[which(samples == 1)]
p[samp] <- p
pi.save <- pi.save + 1 / iter * p
est.mn.dbh[i] <- 1 / N * sum(dbh.pps / probs) # check these
est.var.dbh[i] <- (1 / N) * var(dbh.pps / probs)
est.mn.bio[i] <- 1 / N * sum(bio.pps / probs) # check these
est.var.bio[i] <- (1 / N) * var(bio.pps / probs)
model.pps <- lm(log(bio.pps) ~ log(dbh.pps))
coefs[i, ] <- model.pps$coef
bio.fit[[i]] <- exp(model.pps$coef[1]) * dbh^model.pps$coef[2]
model.srs <- lm(log((bio*exp(error))[samp.srs]) ~ log(dbh[samp.srs]))
bio.fit.srs[[i]] <- exp(model.srs$coef[1]) * dbh^model.srs$coef[2]
model.pps.weight <- lm(log(bio.pps) ~ log(dbh.pps), weights = 1 / fn(dbh.pps))
bio.fit.weight[[i]] <- exp(model.pps.weight$coef[1]) * dbh^model.pps.weight$coef[2]
}
#load("pps.test.RData")
apply(coefs, 2, mean) ## Looks pretty unbiased to me
c(log(a), b)
hist(pi.save - cdffn(dbh)); abline(v = 0, lwd = 8)
N
mean(pi.save - cdffn(dbh))
1,3/4,1,1,3/4,2/3,3/4,1,1,1,2/3,3/4,1,1,1,1,1,1,3/4,2/3,3/4,2/3,1/2,1/2), nrow = 3)
1, 3/4, 1, 1, 3/4, 2/3, 3/4, 1, 1, 1, 2/3, 3/4, 1, 1, 1, 1, 1, 1, 3/4, 2/3, 3/4, 2/3, 1/2, 1/2), nrow = 3)
test <- matrix(c(1, 1, 1, 1, 1, 1, 1/2, 1/2, 1/3, 1/4, 1/4, 1/3, 1/2, 1/2, 1/3, 1/4, 1/3, 1/4, 1/2, 1/2, 1/3, 1/4, 1/3, 1/4,
1, 1, 2/3, 1/2, 2/3, 1/2, 1, 1, 1, 1, 1, 1, 2/3, 1/2, 1/2, 1/2, 1/2, 1/3, 2/3, 1/2, 1/2, 1/2, 1/2, 1/3,
1, 3/4, 1, 1, 3/4, 2/3, 3/4, 1, 1, 1, 2/3, 3/4, 1, 1, 1, 1, 1, 1, 3/4, 2/3, 3/4, 2/3, 1/2, 1/2), nrow = 3)
test
rsum(test)
apply(test, 1, sum)
apply(test, 2, sum)
apply(test, 1, sum)
1, 3/4, 1, 1, 3/4, 2/3, 3/4, 1, 1, 1, 2/3, 3/4, 1, 1, 1, 1, 1, 1, 3/4, 2/3, 3/4, 2/3, 1/2, 1/2), byrow = TRUE, nrow = 3)
test <- matrix(c(1, 1, 1, 1, 1, 1, 1/2, 1/2, 1/3, 1/4, 1/4, 1/3, 1/2, 1/2, 1/3, 1/4, 1/3, 1/4, 1/2, 1/2, 1/3, 1/4, 1/3, 1/4,
1, 1, 2/3, 1/2, 2/3, 1/2, 1, 1, 1, 1, 1, 1, 2/3, 1/2, 1/2, 1/2, 1/2, 1/3, 2/3, 1/2, 1/2, 1/2, 1/2, 1/3,
1, 3/4, 1, 1, 3/4, 2/3, 3/4, 1, 1, 1, 2/3, 3/4, 1, 1, 1, 1, 1, 1, 3/4, 2/3, 3/4, 2/3, 1/2, 1/2), byrow = TRUE, nrow = 3)
apply(test, 1, sum)
apply(test, 1, sum)/24
as.fractions(apply(test, 1, sum)/24)
library(MASS)
as.fractions(apply(test, 1, sum)/24)
144/48
75/144
25/48
144/4
75-36
98-72
144/36
36/4
install.packages("knitr")
library(permute)
library(MASS)
install.packages('permute')
library(permute)
library(MASS)
ctrl <- how(maxperm = 10000000)
N <- 7
perm.mat <- rbind(1:N, allPerms(N, control = ctrl))
pi <- matrix(nrow = dim(perm.mat)[1], ncol = dim(perm.mat)[2])
for(i in 1:dim(perm.mat)[1]){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
#	pi[i,] <- pi[i, ][perm.mat[i,]]
}
apply(pi, 2, mean)
as.fractions(apply(pi, 2, mean))
N <- 8
perm.mat <- rbind(1:N, allPerms(N, control = ctrl))
pi <- matrix(nrow = dim(perm.mat)[1], ncol = dim(perm.mat)[2])
for(i in 1:dim(perm.mat)[1]){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
#	pi[i,] <- pi[i, ][perm.mat[i,]]
}
apply(pi, 2, mean)
as.fractions(apply(pi, 2, mean))
15680/7840
15680/1615
15680/3321
15680/3136
15680/5207
15680/2240
1657/3
1657/5
1657/7
1657/9
1657/11
1657/13
1657/17
1657/19
1657/23
1657/27
1657/29
1657/31
1657/33
1657/37
1657/39
1657/41
as.fractions(apply(pi, 2, mean))
1615/3
1615/5
323/3
323/7
323/11
323/13
323/17
5*17*19
as.fractions(apply(pi, 2, mean))
3321/3
1107/3
369/3
123/3
41/3
41/7
15680/7840
15680/3321
15680/3136
as.fractions(apply(pi, 2, mean))
15680/5027
5027/3
50275
5027/5
5027/7
5027/11
457/11
457/13
457/17
457/19
457/21
457/23
as.fractions(apply(pi, 2, mean))
15680/2
15680/2/2
15680/2/2/2
15680/2/2/2/2
15680/2/2/2/2/2
15680/2/2/2/2/2/2
15680/(2^6)
15680/(2^7)
15680/(2^6)
15680/(2^6)/3
15680/(2^6)/5
49/7
11*457
as.fractions(apply(pi, 2, mean))
## N=8 denominator of 2*2*2*2*2*2*5*7*7 * 5*17*19 * 3*3*3*3*41 * 11*457
2*2*2*2*2*2*5*7*7 * 5*17*19 * 3*3*3*3*41 * 11*457
factorial(8)
factorial(8)^2
library(permute)
library(MASS)
ctrl <- how(maxperm = 10000000)
N <- 8
perm.mat <- rbind(1:N, allPerms(N, control = ctrl))
pi <- matrix(nrow = dim(perm.mat)[1], ncol = dim(perm.mat)[2])
for(i in 1:dim(perm.mat)[1]){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
#	pi[i,] <- pi[i, ][perm.mat[i,]]
}
apply(pi, 2, mean)
as.fractions(apply(pi, 2, mean))
