install.packages('rlecuyer')
library(xtable)
library(parallel)
library(snowfall)
library(rlecuyer)
cps <- detectCores()
sfInit(parallel = TRUE, cpus = cps)
sfClusterSetupRNG()
##
## Simulate dbh
##
N <- 400 # finite population size
n <- 100 # expected sample size
##
## Start with a population that is a mixture of Gamma Distributions
##
alpha <- c(2, 4, 6, 8) # gamma mixture parameter
beta <- c(12, 10, 8, 6) # gamma mixture parameter
dbh <- make.gamma.mixture(N, alpha, beta)
##
## Plot DBH
##
layout(matrix(1:4, 2, 2))
for(i in 1:4){ # plot the four distibutions to mix
curve(dgamma(x, alpha[i], beta[i]), from = 0, to = 4)
}
par(mfrow = c(1, 1))
#pdf(file = 'dbh1.pdf')
hist(dbh, breaks = 20)
#dev.off()
##
## True mean and variance for DBH
##
dbh.mn <- mean(dbh)
dbh.var <- var(dbh)
##
## Simulate Biomass
##
b0 <- 5
b1 <- 2
s2 <- 1/4
bio <- make.sim.biomass(dbh, b0, b1, s2)
bio.mn <- mean(bio)
bio.var <- var(bio)
##
## Plot Data
##
#make.model.plot(dbh, bio, file = "fullModel.pdf")
pdf(file = 'dbhModel.pdf')
make.model.plot(dbh, bio)
dev.off()
##
## empirical estimator results
##
iter <- 10000
sfExportAll()
temp.srs <- sfSapply(1:iter, make.est.result, dbh = dbh, bio = bio, n = n, method = 'srs')
summary(temp.srs)
mean(temp.srs)
var(temp.srs)
temp.pps <- sfSapply(1:iter, make.est.result, dbh = dbh, bio = bio, n = n, method = 'pps')
summary(temp.pps)
mean(temp.pps)
var(temp.pps)
temp.ecdf <- sfSapply(1:iter, make.est.result, dbh = dbh, bio = bio, n = n, method = 'ecdf')
summary(temp.ecdf)
mean(temp.ecdf)
var(temp.ecdf)
temp.design <- sfSapply(1:iter, make.est.result, dbh = dbh, bio = bio, n = n, method = 'design')
summary(temp.design)
mean(temp.design)
var(temp.design)
temp.strat <- sfSapply(1:iter, make.est.result, dbh = dbh, bio = bio, n = n, method = 'strat')
summary(temp.strat)
mean(temp.strat)
var(temp.strat)
temp.design.pps <- sfSapply(1:iter, make.est.result, dbh = dbh, bio = bio, n = n, method = 'strat')
summary(temp.design.pps)
mean(temp.design.pps)
var(temp.design.pps)
tab <- cbind(c(mean(temp.srs), mean(temp.ecdf), mean(temp.pps), mean(temp.design), mean(temp.design.pps), mean(temp.strat)) - bio.mn, c(var(temp.srs), var(temp.ecdf), var(temp.pps), var(temp.design), var(temp.design.pps), var(temp.strat)) / var(temp.srs))
rownames(tab) = c('SRS', 'ECDF', 'PPS', "AECDF", "APPS", "STSI")
colnames(tab) <- c('Bias', 'Relative Efficiency')
xtable(tab)
out <- make.samp(dbh, bio, n, method = 'strat')
#make.model.plot(out$dbh, out$bio)
dbh.mn
temp.design.pps <- sfSapply(1:iter, make.est.result, dbh = dbh, bio = bio, n = n, method = 'design.pps')
summary(temp.design.pps)
mean(temp.design.pps)
var(temp.design.pps)
##
## libraries and functions
##
source("sequential.functions.R")
library(xtable)
library(parallel)
library(snowfall)
library(rlecuyer)
cps <- detectCores()
sfInit(parallel = TRUE, cpus = cps)
sfClusterSetupRNG()
##
## Simulate dbh
##
N <- 400 # finite population size
n <- 100 # expected sample size
##
## Start with a population that is a mixture of Gamma Distributions
##
alpha <- c(2, 4, 6, 8) # gamma mixture parameter
beta <- c(12, 10, 8, 6) # gamma mixture parameter
dbh <- make.gamma.mixture(N, alpha, beta)
##
## Plot DBH
##
layout(matrix(1:4, 2, 2))
for(i in 1:4){ # plot the four distibutions to mix
curve(dgamma(x, alpha[i], beta[i]), from = 0, to = 4)
}
par(mfrow = c(1, 1))
#pdf(file = 'dbh1.pdf')
hist(dbh, breaks = 20)
#dev.off()
##
## True mean and variance for DBH
##
dbh.mn <- mean(dbh)
dbh.var <- var(dbh)
##
## Simulate Biomass
##
b0 <- 5
b1 <- 2
s2 <- 1/4
bio <- make.sim.biomass(dbh, b0, b1, s2)
bio.mn <- mean(bio)
bio.var <- var(bio)
##
## Plot Data
##
#make.model.plot(dbh, bio, file = "fullModel.pdf")
pdf(file = 'dbhModel.pdf')
make.model.plot(dbh, bio)
dev.off()
##
## empirical estimator results
##
iter <- 10000
sfExportAll()
temp.srs <- sfSapply(1:iter, make.est.result, dbh = dbh, bio = bio, n = n, method = 'srs')
summary(temp.srs)
mean(temp.srs)
var(temp.srs)
temp.pps <- sfSapply(1:iter, make.est.result, dbh = dbh, bio = bio, n = n, method = 'pps')
summary(temp.pps)
mean(temp.pps)
var(temp.pps)
temp.ecdf <- sfSapply(1:iter, make.est.result, dbh = dbh, bio = bio, n = n, method = 'ecdf')
summary(temp.ecdf)
mean(temp.ecdf)
var(temp.ecdf)
temp.design <- sfSapply(1:iter, make.est.result, dbh = dbh, bio = bio, n = n, method = 'design')
summary(temp.design)
mean(temp.design)
var(temp.design)
temp.strat <- sfSapply(1:iter, make.est.result, dbh = dbh, bio = bio, n = n, method = 'strat')
summary(temp.strat)
mean(temp.strat)
var(temp.strat)
temp.design.pps <- sfSapply(1:iter, make.est.result, dbh = dbh, bio = bio, n = n, method = 'design.pps')
summary(temp.design.pps)
mean(temp.design.pps)
var(temp.design.pps)
tab <- cbind(c(mean(temp.srs), mean(temp.ecdf), mean(temp.pps), mean(temp.design), mean(temp.design.pps), mean(temp.strat)) - bio.mn, c(var(temp.srs), var(temp.ecdf), var(temp.pps), var(temp.design), var(temp.design.pps), var(temp.strat)) / var(temp.srs))
rownames(tab) = c('SRS', 'ECDF', 'PPS', "AECDF", "APPS", "STSI")
colnames(tab) <- c('Bias', 'Relative Efficiency')
xtable(tab)
out <- make.samp(dbh, bio, n, method = 'strat')
#make.model.plot(out$dbh, out$bio)
dbh.mn
temp.design.pps <- sapply(1:iter, make.est.result, dbh = dbh, bio = bio, n = n, method = 'design.pps')
out <- make.samp(dbh, bio, n, method)
method = 'design.pps'
out <- make.samp(dbh, bio, n, method)
n.samp <- length(out$samp)
n.samp
out
out <- make.samp(dbh, bio, n, method)
N <- length(dbh)
N
idx <- sample(1:N)
ids
idx
p <- vector(length = N)
p
make.samp <- function(dbh, bio, n, method = 'srs'){
N <- length(dbh)
if(method == 'srs'){
p <- n * rep(1 / N, N)
samp <- sample(1:N, n, prob = p)
}
if(method == 'pps'){
p <- n * dbh / sum(dbh)
samp <- sample(1:N, n, prob = p)
}
if(method == 'ecdf'){
p <- 2 * n / N * ecdf(dbh)(dbh)
samp <- which(rbinom(1:N, 1, p) == 1)
}
if(method == 'design'){
idx <- sample(1:N)
p <- vector(length = N)
for(k in 1:N){
x <- dbh[idx[1:k]]
fn <- ecdf(x)
p[k] <- fn(x)[k]
}
p <- p * 2 * n / N # potential sample size adjustment
samp <- which(rbinom(N, 1, p) == 1)
idx <- order(dbh)
#p <- make.pi(N)
}
if(method == 'design.pps'){
idx <- sample(1:N)
p <- vector(length = N)
dbh.sum <- 0
for(k in 1:N){
p[k] <- dbh[idx[k]] / sum(dbh[idx[1:k]])
# 				x <- dbh[idx[1:k]]
# 				fn <- ecdf(x)
# 				p[k] <- fn(x)[k]
}
p <- p * 2 * n / N # potential sample size adjustment
samp <- which(rbinom(N, 1, p) == 1)
idx <- order(dbh)
#p <- make.pi(N)
}
# 	if(method == 'strat'){
# 	  if(n %% 3 == 0){
# 		  n1 <- n / 3
#   		n2 <- n / 3
# 	   	n3 <- n / 3
#   	}
# 	  if(n %% 3 == 1){
# 		  n1 <- floor(n / 3)
#   		n2 <- floor(n / 3)
# 	   	n3 <- ceiling(n / 3)
#   	}
# 	  if(n %% 3 == 2){
# 		  n1 <- floor(n / 3)
# 		  n2 <- ceiling(n / 3)
# 		  n3 <- ceiling(n / 3)
#   	}
if(method == 'strat'){
if(n %% 3 == 0){
n1 <- n / 6
n2 <- n / 3
n3 <- n / 2
}
if(n %% 3 == 1){
n1 <- floor(n / 6)
n2 <- floor(n / 3)
n3 <- ceiling(n / 2)
}
if(n %% 3 == 2){
n1 <- floor(n / 6)
n2 <- ceiling(n / 3)
n3 <- ceiling(n / 2)
}
N <- length(dbh)
dbh.quant <- make.gamma.mixture(N, alpha = c(2, 4, 6, 8), beta = c(12, 10, 8, 6))
# 	  quant <- quantile(dbh.quant, probs = c(1/3, 2/3))
quant <- quantile(dbh.quant, probs = c(1/6, 1/3))
q.idx.1 <- which(dbh < quant[1])
q.idx.2 <- which(quant[1] <= dbh & dbh < quant[2])
q.idx.3 <- which(quant[2] <= dbh)
samp1 <- sample(q.idx.1, n1)
samp2 <- sample(q.idx.2, n2)
samp3 <- sample(q.idx.3, n3)
samp <- c(samp1, samp2, samp3)
dbh.samp1 <- dbh[samp1]
dbh.samp2 <- dbh[samp2]
dbh.samp3 <- dbh[samp3]
bio.samp1 <- bio[samp1]
bio.samp2 <- bio[samp2]
bio.samp3 <- bio[samp3]
nh <- c(length(samp1), length(samp2), length(samp3))
Nh <- c(length(q.idx.1), length(q.idx.2), length(q.idx.3))
muh.dbh <- c(mean(dbh.samp1), mean(dbh.samp2), mean(dbh.samp3))
sh.dbh <- c(var(dbh.samp1), var(dbh.samp2), var(dbh.samp3))
muh.bio <- c(mean(bio.samp1), mean(bio.samp2), mean(bio.samp3))
dbh.mn <- 1 / N * sum(Nh * muh.dbh)
bio.mn <- 1 / N * sum(Nh * muh.bio)
dbh.samp <- dbh[samp]
bio.samp <- bio[samp]
list(dbh = dbh.samp, dbh.mn = dbh.mn, bio = bio.samp, bio.mn = bio.mn, quant = quant, samp = samp)
} else {
prob <- p[samp]
dbh.samp <- dbh[samp]
dbh.mn <- 1 / N * sum(dbh.samp / prob)
bio.samp <- bio[samp]
bio.mn <- 1 / N * sum(bio.samp / prob)
list(dbh = dbh.samp, dbh.mn = dbh.mn, bio = bio.samp, bio.mn = bio.mn, p = p, samp = samp)
}
}
temp.design.pps <- sfSapply(1:iter, make.est.result, dbh = dbh, bio = bio, n = n, method = 'design.pps')
sfExportAll()
temp.design.pps <- sfSapply(1:iter, make.est.result, dbh = dbh, bio = bio, n = n, method = 'design.pps')
temp.design.pps <- sapply(1:iter, make.est.result, dbh = dbh, bio = bio, n = n, method = 'design.pps')
n.samp
out <- make.samp(dbh, bio, n, method)
out
n.samp <- length(out$samp)
n.samp
idx <- sample(1:N)
p <- vector(length = N)
dbh.sum <- 0
for(k in 1:N){
p[k] <- dbh[idx[k]] / sum(dbh[idx[1:k]])
# 				x <- dbh[idx[1:k]]
# 				fn <- ecdf(x)
# 				p[k] <- fn(x)[k]
}
p <- p * 2 * n / N # potential sample size adjustment
p
samp <- which(rbinom(N, 1, p) == 1)
samp
n
p
idx <- sample(1:N)
p <- vector(length = N)
dbh.sum <- 0
for(k in 1:N){
p[k] <- dbh[idx[k]] / sum(dbh[idx[1:k]])
# 				x <- dbh[idx[1:k]]
# 				fn <- ecdf(x)
# 				p[k] <- fn(x)[k]
}
p
p[1:10]
samp <- which(rbinom(N, 1, p) == 1)
idx <- order(dbh)
samp
n
2 * n / N
N
p
k=2
dbh[idx[k]]
sum(dbh[idx[1:k]])
dbh[idx[1:k]]
p <- p * n # potential sample size adjustment
samp <- which(rbinom(N, 1, p) == 1)
samp
p <- min(p * n, 1) # potential sample size adjustment
samp <- which(rbinom(N, 1, p) == 1)
samp
length(samp)
p <- min(p * n / N, 1) # potential sample size adjustment
#       p <- p * 2 * n / N # potential sample size adjustment
samp <- which(rbinom(N, 1, p) == 1)
length(samp)
if(method == 'design.pps'){
idx <- sample(1:N)
p <- vector(length = N)
dbh.sum <- 0
for(k in 1:N){
p[k] <- dbh[idx[k]] / sum(dbh[idx[1:k]])
# 				x <- dbh[idx[1:k]]
# 				fn <- ecdf(x)
# 				p[k] <- fn(x)[k]
}
p <- min(p * n / N, 1) # potential sample size adjustment
#       p <- p * 2 * n / N # potential sample size adjustment
samp <- which(rbinom(N, 1, p) == 1)
idx <- order(dbh)
#p <- m
# 	if
}
p
idx <- sample(1:N)
p <- vector(length = N)
dbh.sum <- 0
for(k in 1:N){
p[k] <- dbh[idx[k]] / sum(dbh[idx[1:k]])
# 				x <- dbh[idx[1:k]]
# 				fn <- ecdf(x)
# 				p[k] <- fn(x)[k]
}
p <- min(p * n / N, 1) # potential sample size adjustment
#       p <- p * 2 * n / N # potential sample size adjustment
samp <- which(rbinom(N, 1, p) == 1)
idx <- order(dbh)
length(samp)
idx <- sample(1:N)
p <- vector(length = N)
dbh.sum <- 0
for(k in 1:N){
p[k] <- dbh[idx[k]] / sum(dbh[idx[1:k]])
# 				x <- dbh[idx[1:k]]
# 				fn <- ecdf(x)
# 				p[k] <- fn(x)[k]
}
p <- min(p * n / N, 1) # potential sample size adjustment
#       p <- p * 2 * n / N # potential sample size adjustment
samp <- which(rbinom(N, 1, p) == 1)
idx <- order(dbh)
length(samp)
idx <- sample(1:N)
p <- vector(length = N)
dbh.sum <- 0
for(k in 1:N){
p[k] <- dbh[idx[k]] / sum(dbh[idx[1:k]])
# 				x <- dbh[idx[1:k]]
# 				fn <- ecdf(x)
# 				p[k] <- fn(x)[k]
}
p <- min(p * n , 1) # potential sample size adjustment
#       p <- p * 2 * n / N # potential sample size adjustment
samp <- which(rbinom(N, 1, p) == 1)
idx <- order(dbh)
length(samp)
idx <- sample(1:N)
p <- vector(length = N)
dbh.sum <- 0
for(k in 1:N){
p[k] <- dbh[idx[k]] / sum(dbh[idx[1:k]])
# 				x <- dbh[idx[1:k]]
# 				fn <- ecdf(x)
# 				p[k] <- fn(x)[k]
}
p <- min(p * n , 1) # potential sample size adjustment
#       p <- p * 2 * n / N # potential sample size adjustment
samp <- which(rbinom(N, 1, p) == 1)
idx <- order(dbh)
length(samp)
idx <- sample(1:N)
p <- vector(length = N)
dbh.sum <- 0
for(k in 1:N){
p[k] <- dbh[idx[k]] / sum(dbh[idx[1:k]])
# 				x <- dbh[idx[1:k]]
# 				fn <- ecdf(x)
# 				p[k] <- fn(x)[k]
}
p <- min(p * n , 1) # potential sample size adjustment
#       p <- p * 2 * n / N # potential sample size adjustment
samp <- which(rbinom(N, 1, p) == 1)
idx <- order(dbh)
length(samp)
p <- min(p * n , 1) # potential sample size adjustment
idx <- sample(1:N)
p <- vector(length = N)
dbh.sum <- 0
for(k in 1:N){
p[k] <- dbh[idx[k]] / sum(dbh[idx[1:k]])
# 				x <- dbh[idx[1:k]]
# 				fn <- ecdf(x)
# 				p[k] <- fn(x)[k]
}
p <- min(p * n , 1) # potential sample size adjustment
#       p <- p * 2 * n / N # potential sample size adjustment
samp <- which(rbinom(N, 1, p) == 1)
idx <- order(dbh)
samp
length(samp)
idx <- sample(1:N)
p <- vector(length = N)
dbh.sum <- 0
for(k in 1:N){
p[k] <- dbh[idx[k]] / sum(dbh[idx[1:k]])
# 				x <- dbh[idx[1:k]]
# 				fn <- ecdf(x)
# 				p[k] <- fn(x)[k]
}
p <- min(p * 2 * n , 1) # potential sample size adjustment
#       p <- p * 2 * n / N # potential sample size adjustment
samp <- which(rbinom(N, 1, p) == 1)
idx <- order(dbh)
length(samp)
idx <- sample(1:N)
p <- vector(length = N)
dbh.sum <- 0
for(k in 1:N){
p[k] <- dbh[idx[k]] / sum(dbh[idx[1:k]])
# 				x <- dbh[idx[1:k]]
# 				fn <- ecdf(x)
# 				p[k] <- fn(x)[k]
}
p <- min(p * 2 * n , 1) # potential sample size adjustment
#       p <- p * 2 * n / N # potential sample size adjustment
samp <- which(rbinom(N, 1, p) == 1)
idx <- order(dbh)
length(samp)
idx <- sample(1:N)
p <- vector(length = N)
dbh.sum <- 0
for(k in 1:N){
p[k] <- dbh[idx[k]] / sum(dbh[idx[1:k]])
# 				x <- dbh[idx[1:k]]
# 				fn <- ecdf(x)
# 				p[k] <- fn(x)[k]
}
p <- min(p * 2 * n , 1) # potential sample size adjustment
#       p <- p * 2 * n / N # potential sample size adjustment
samp <- which(rbinom(N, 1, p) == 1)
idx <- order(dbh)
length(samp)
dbh
bio
cor(dbh, bio)
