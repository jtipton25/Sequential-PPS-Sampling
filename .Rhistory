<<<<<<< HEAD
##
## Sequential PPS design
##
##
## Sample the first element (x1) with probability 1
## Sample the second element (x2) with probability 1 if x2 > x1
##                                                 1/2 if x2 <= x1
##
## Sample the third element (x3) with probability 1 if x3 > x1 & x2
##                                                2/3 if x3 > x1 & x3 < x2
##                                                2/3 if x3 > x2 & x3 < x1
##                                                1/3 if x3 < x1 & x2
##
## And so on
##
##
## Testing the behavior of the probability of being sampled pi_i for one population
##
#dbh <- runif(N)
#alpha <- 2
#beta <- 6
hist(dbh, freq = FALSE, breaks = 20)
#curve(dgamma(x, alpha, beta))
iter <- 1000
est.mn.dbh <- vector(length = iter)
est.var.dbh <- vector(length = iter)
est.mn.bio <- vector(length = iter)
est.var.bio <- vector(length = iter)
bio.fit <- vector(mode = 'list', length = iter)
bio.fit.weight <- vector(mode = 'list', length = iter)
bio.fit.srs <- vector(mode = 'list', length = iter)
pi.save <- rep(0, length = N)
n.save <- vector(length = iter)
s2.core <- 1/8 # Sampling error from coring tree
coefs <- matrix(nrow = iter, ncol = 2)
for(i in 1:iter){
if(i %% 100 == 0){
cat(i, ' ')
}
p <- vector(length = N)
samp.srs <- sample(1:N, n) #SRS sampling for comparison
samp <- sample(1:N)
dbh.samp <- dbh[samp]
bio.samp <- bio[samp]
for(k in 1:N){
x <- dbh.samp[1:k]
fn <- ecdf(x)
p[k] <- fn(x)[k]
}
p <- p * 2 * n / N #potential sample size adjustment
samples <- rbinom(N, 1, p)
dbh.pps <- dbh.samp[which(samples == 1)]
error <- rnorm(N, 0, s2.core)
bio.pps <- (bio.samp*exp(error))[which(samples == 1)] #exponential error due to measurement error sampling the cores, not sampling design
n.save[i] <- sum(samples)
probs <- p[which(samples == 1)]
p[samp] <- p
pi.save <- pi.save + 1 / iter * p
est.mn.dbh[i] <- 1 / N * sum(dbh.pps / probs) # check these
est.var.dbh[i] <- (1 / N) * var(dbh.pps / probs)
est.mn.bio[i] <- 1 / N * sum(bio.pps / probs) # check these
est.var.bio[i] <- (1 / N) * var(bio.pps / probs)
model.pps <- lm(log(bio.pps) ~ log(dbh.pps))
coefs[i, ] <- model.pps$coef
bio.fit[[i]] <- exp(model.pps$coef[1]) * dbh^model.pps$coef[2]
model.srs <- lm(log((bio*exp(error))[samp.srs]) ~ log(dbh[samp.srs]))
bio.fit.srs[[i]] <- exp(model.srs$coef[1]) * dbh^model.srs$coef[2]
model.pps.weight <- lm(log(bio.pps) ~ log(dbh.pps), weights = 1 / fn(dbh.pps))
bio.fit.weight[[i]] <- exp(model.pps.weight$coef[1]) * dbh^model.pps.weight$coef[2]
}
apply(coefs, 2, mean) ## Looks pretty unbiased to me
c(log(a), b)
mean(est.mn.dbh)
var(est.mn.dbh)
mean(est.var.dbh)
mean(dbh)
var(dbh) / N^2
mean(n.save)
## Plots suggest CLT behavior
layout(matrix(c(1:4), nrow = 2))
hist(est.mn.dbh, freq = FALSE, breaks = 20)
curve(dnorm(x, mean(est.mn.dbh), sqrt(N*mean(est.var.dbh))), add = TRUE)
## Density function for dbh
#curve((1/4 * dbeta(x, alpha[1], beta[1]) + 1/4 * dbeta(x, alpha[2], beta[2]) + 1/4 * dbeta(x, alpha[3], beta[3]) + 1/4 * dbeta(x, alpha[4], beta[4])), ylab = "")
hist(est.mn.bio, freq = FALSE, breaks = 20)
curve(dnorm(x, mean(est.mn.bio), sqrt(N*var(est.var.bio))), add = TRUE)
hist(n.save) # mean is about 1/2 number of trees N for this distribution
cdffn <- ecdf(dbh)
hist(pi.save - 2 * n / N * cdffn(dbh) - 1/N, breaks = 20) # Not the same as pps sampling
mean(pi.save - 2 * n / N * cdffn(dbh)- 1/N)
MSPE.srs <- vector(length = iter)
MSPE.pps <- vector(length = iter)
MSPE.pps.weight <- vector(length = iter)
for(i in 1:iter){
MSPE.srs[i] <- mean((bio.fit.srs[[i]] - bio)^2)
MSPE.pps[i] <- mean((bio.fit[[i]] - bio)^2)
MSPE.pps.weight[i] <- mean((bio.fit.weight[[i]] - bio)^2)
}
mean(MSPE.srs)
mean(MSPE.pps)
mean(MSPE.pps.weight)
##
##
##
##
## Informative sampling test idea
##
model.no.informative <- lm(log(bio.pps) ~ log(dbh.pps))
model.informative <- lm(log(bio.pps) ~ log(dbh.pps) + 1 / fn(dbh.pps) + log(dbh.pps) * 1 / fn(dbh.pps))
anova(model.no.informative, model.informative)
save.image(file = "pps.test.RData")
hist(pi.save - 2 * n / N * cdffn(dbh), freq = FALSE)
lines(density(pi.save - 2 * n / N * cdffn(dbh)))
load("~/Sequential PPS Sampling/pps.test.RData")
load.image("pps.test.RData")
load.image(pps.test.RData)
load(pps.test.RData)
#load("pps.test.RData")
load("pps.test.RData")
mean(pi.save - 2 * n / N * cdffn(dbh)- 1/N)
hist(pi.save - 2 * n / N * cdffn(dbh) - 1/N, breaks = 20) # Not the same as pps sampling
hist(pi.save - 2 * n / N * cdffn(dbh), breaks = 20) # Not the same as pps sampling
cdffn(dbh)
sort(cdffn(dbh))
hist(pi.save - 2 * n / N * cdffn(dbh) - 1/N, breaks = 20) # Not the same as pps sampling
mean(pi.save - 2 * n / N * cdffn(dbh)- 1/N)
mean(pi.save - 2 * n / N * cdffn(dbh))
hist(pi.save - 2 * n / N * cdffn(dbh))
min(pi.save - 2 * n / N * cdffn(dbh))
max(pi.save - 2 * n / N * cdffn(dbh))
pi.save
cdffn(dbh)
pi.save - cdffn(dbh)
iter <- 1000
est.mn.dbh <- vector(length = iter)
est.var.dbh <- vector(length = iter)
est.mn.bio <- vector(length = iter)
est.var.bio <- vector(length = iter)
bio.fit <- vector(mode = 'list', length = iter)
bio.fit.weight <- vector(mode = 'list', length = iter)
bio.fit.srs <- vector(mode = 'list', length = iter)
pi.save <- rep(0, length = N)
n.save <- vector(length = iter)
s2.core <- 1/8 # Sampling error from coring tree
coefs <- matrix(nrow = iter, ncol = 2)
for(i in 1:iter){
if(i %% 100 == 0){
cat(i, ' ')
}
p <- vector(length = N)
samp.srs <- sample(1:N, n) #SRS sampling for comparison
samp <- sample(1:N)
dbh.samp <- dbh[samp]
bio.samp <- bio[samp]
for(k in 1:N){
x <- dbh.samp[1:k]
fn <- ecdf(x)
p[k] <- fn(x)[k]
}
#	p <- p * 2 * n / N #potential sample size adjustment
samples <- rbinom(N, 1, p)
dbh.pps <- dbh.samp[which(samples == 1)]
error <- rnorm(N, 0, s2.core)
bio.pps <- (bio.samp*exp(error))[which(samples == 1)] #exponential error due to measurement error sampling the cores, not sampling design
n.save[i] <- sum(samples)
probs <- p[which(samples == 1)]
p[samp] <- p
pi.save <- pi.save + 1 / iter * p
est.mn.dbh[i] <- 1 / N * sum(dbh.pps / probs) # check these
est.var.dbh[i] <- (1 / N) * var(dbh.pps / probs)
est.mn.bio[i] <- 1 / N * sum(bio.pps / probs) # check these
est.var.bio[i] <- (1 / N) * var(bio.pps / probs)
model.pps <- lm(log(bio.pps) ~ log(dbh.pps))
coefs[i, ] <- model.pps$coef
bio.fit[[i]] <- exp(model.pps$coef[1]) * dbh^model.pps$coef[2]
model.srs <- lm(log((bio*exp(error))[samp.srs]) ~ log(dbh[samp.srs]))
bio.fit.srs[[i]] <- exp(model.srs$coef[1]) * dbh^model.srs$coef[2]
model.pps.weight <- lm(log(bio.pps) ~ log(dbh.pps), weights = 1 / fn(dbh.pps))
bio.fit.weight[[i]] <- exp(model.pps.weight$coef[1]) * dbh^model.pps.weight$coef[2]
}
N <- 1000
n <- 100
#alpha <- 2
#beta <- 6
#curve(dgamma(x, alpha, beta))
#dbh <- rgamma(N, alpha, beta)
#dbh <- runif(N)
alpha <- c(2, 4, 6, 8)
beta <- c(12, 10, 8, 6)
layout(matrix(1:4, 2, 2))
for(i in 1:4){
curve(dgamma(x, alpha[i], beta[i]), from = 0, to = 4)
}
samp.density <- sample(1:4, N, replace = TRUE)
dbh <- 5 + 10 * rgamma(N, alpha[samp.density], beta[samp.density])
par(mfrow = c(1, 1))
hist(dbh, breaks = 20)
truth.dbh <- 1 / N * sum(dbh)
truth.dbh
N <- 1000
n <- 100
#alpha <- 2
#beta <- 6
#curve(dgamma(x, alpha, beta))
#dbh <- rgamma(N, alpha, beta)
#dbh <- runif(N)
alpha <- c(2, 4, 6, 8)
beta <- c(12, 10, 8, 6)
layout(matrix(1:4, 2, 2))
for(i in 1:4){
curve(dgamma(x, alpha[i], beta[i]), from = 0, to = 4)
}
samp.density <- sample(1:4, N, replace = TRUE)
dbh <- 5 + 10 * rgamma(N, alpha[samp.density], beta[samp.density])
par(mfrow = c(1, 1))
hist(dbh, breaks = 20)
truth.dbh <- 1 / N * sum(dbh)
truth.dbh
##
## Simulate Biomass
##
a <- 2
b <- 2
s2 <- 1 / 4
epsilon <- rnorm(N, 0, s2)
bio <- a * dbh ^ b * exp(epsilon)
bio[bio < 0]
plot(log(bio) ~ log(dbh))
model <- lm(log(bio) ~ log(dbh))
abline(model)
plot(resid(model) ~ fitted(model))
abline(h=0)
plot(bio ~ dbh)
curve(exp(model$coeff[1]) * x^model$coeff[2], add = TRUE)
truth.bio <- mean(bio)
##
## True PPS sampling design
##
p <- dbh / sum(dbh)
hist(p)
samp <- sample(1:N, n, prob = p)
estimate.dbh <- 1 / N * sum(1 / n * dbh[samp] / p[samp])
estimate.bio <- 1 / N * sum(1 / n * bio[samp] / p[samp])
truth.dbh - estimate.dbh
truth.bio - estimate.bio
##
## Compare True allometric relationship to pps allometric relationship
##
model.pps <- lm(log(bio[samp]) ~ log(dbh[samp]))
model
model.pps
layout(matrix(1:4, 2))
plot(log(bio) ~ log(dbh))
abline(model)
plot(bio ~ dbh)
curve(exp(model$coeff[1]) * x^model$coeff[2], add = TRUE)
plot(log(bio[samp]) ~ log(dbh[samp]))
abline(model.pps)
plot(bio[samp] ~ dbh[samp])
curve(exp(model.pps$coeff[1]) * x^model.pps$coeff[2], add = TRUE)
##
## Estimate Bias from pps sampling
##
iter <- 100
coefs <- matrix(nrow = iter, ncol = 2)
for(j in 1:iter){
samp <-  sample(1:N, n, prob = p)
model.pps <- lm(log(bio[samp]) ~ log(dbh[samp]))
coefs[j, ] <- model.pps$coef
}
apply(coefs, 2, mean)
c(log(a), b)
## Seems to be unbiasedly estimating the regression parameters
##
## Sequential PPS design
##
##
## Sample the first element (x1) with probability 1
## Sample the second element (x2) with probability 1 if x2 > x1
##                                                 1/2 if x2 <= x1
##
## Sample the third element (x3) with probability 1 if x3 > x1 & x2
##                                                2/3 if x3 > x1 & x3 < x2
##                                                2/3 if x3 > x2 & x3 < x1
##                                                1/3 if x3 < x1 & x2
##
## And so on
##
##
## Testing the behavior of the probability of being sampled pi_i for one population
##
#dbh <- runif(N)
#alpha <- 2
#beta <- 6
hist(dbh, freq = FALSE, breaks = 20)
#curve(dgamma(x, alpha, beta))
iter <- 1000
est.mn.dbh <- vector(length = iter)
est.var.dbh <- vector(length = iter)
est.mn.bio <- vector(length = iter)
est.var.bio <- vector(length = iter)
bio.fit <- vector(mode = 'list', length = iter)
bio.fit.weight <- vector(mode = 'list', length = iter)
bio.fit.srs <- vector(mode = 'list', length = iter)
pi.save <- rep(0, length = N)
n.save <- vector(length = iter)
s2.core <- 1/8 # Sampling error from coring tree
coefs <- matrix(nrow = iter, ncol = 2)
for(i in 1:iter){
if(i %% 100 == 0){
cat(i, ' ')
}
p <- vector(length = N)
samp.srs <- sample(1:N, n) #SRS sampling for comparison
samp <- sample(1:N)
dbh.samp <- dbh[samp]
bio.samp <- bio[samp]
for(k in 1:N){
x <- dbh.samp[1:k]
fn <- ecdf(x)
p[k] <- fn(x)[k]
}
#	p <- p * 2 * n / N #potential sample size adjustment
samples <- rbinom(N, 1, p)
dbh.pps <- dbh.samp[which(samples == 1)]
error <- rnorm(N, 0, s2.core)
bio.pps <- (bio.samp*exp(error))[which(samples == 1)] #exponential error due to measurement error sampling the cores, not sampling design
n.save[i] <- sum(samples)
probs <- p[which(samples == 1)]
p[samp] <- p
pi.save <- pi.save + 1 / iter * p
est.mn.dbh[i] <- 1 / N * sum(dbh.pps / probs) # check these
est.var.dbh[i] <- (1 / N) * var(dbh.pps / probs)
est.mn.bio[i] <- 1 / N * sum(bio.pps / probs) # check these
est.var.bio[i] <- (1 / N) * var(bio.pps / probs)
model.pps <- lm(log(bio.pps) ~ log(dbh.pps))
coefs[i, ] <- model.pps$coef
bio.fit[[i]] <- exp(model.pps$coef[1]) * dbh^model.pps$coef[2]
model.srs <- lm(log((bio*exp(error))[samp.srs]) ~ log(dbh[samp.srs]))
bio.fit.srs[[i]] <- exp(model.srs$coef[1]) * dbh^model.srs$coef[2]
model.pps.weight <- lm(log(bio.pps) ~ log(dbh.pps), weights = 1 / fn(dbh.pps))
bio.fit.weight[[i]] <- exp(model.pps.weight$coef[1]) * dbh^model.pps.weight$coef[2]
}
for(i in 1:iter){
if(i %% 100 == 0){
cat(i, ' ')
}
p <- vector(length = N)
samp.srs <- sample(1:N, n) #SRS sampling for comparison
samp <- sample(1:N)
dbh.samp <- dbh[samp]
bio.samp <- bio[samp]
for(k in 1:N){
x <- dbh.samp[1:k]
fn <- ecdf(x)
p[k] <- fn(x)[k]
}
#	p <- p * 2 * n / N #potential sample size adjustment
samples <- rbinom(N, 1, p)
dbh.pps <- dbh.samp[which(samples == 1)]
error <- rnorm(N, 0, s2.core)
bio.pps <- (bio.samp*exp(error))[which(samples == 1)] #exponential error due to measurement error sampling the cores, not sampling design
n.save[i] <- sum(samples)
probs <- p[which(samples == 1)]
p[samp] <- p
pi.save <- pi.save + 1 / iter * p
est.mn.dbh[i] <- 1 / N * sum(dbh.pps / probs) # check these
est.var.dbh[i] <- (1 / N) * var(dbh.pps / probs)
est.mn.bio[i] <- 1 / N * sum(bio.pps / probs) # check these
est.var.bio[i] <- (1 / N) * var(bio.pps / probs)
model.pps <- lm(log(bio.pps) ~ log(dbh.pps))
coefs[i, ] <- model.pps$coef
bio.fit[[i]] <- exp(model.pps$coef[1]) * dbh^model.pps$coef[2]
model.srs <- lm(log((bio*exp(error))[samp.srs]) ~ log(dbh[samp.srs]))
bio.fit.srs[[i]] <- exp(model.srs$coef[1]) * dbh^model.srs$coef[2]
model.pps.weight <- lm(log(bio.pps) ~ log(dbh.pps), weights = 1 / fn(dbh.pps))
bio.fit.weight[[i]] <- exp(model.pps.weight$coef[1]) * dbh^model.pps.weight$coef[2]
}
cdffn <- ecdf(dbh)
hist(pis.save)
hist(pi.save)
layout(c(1,1))
hist(pi.save)
hist(pi.save - 1/N)
hist(pi.save - 1 - 1/N)
hist(pi.save - 1/2 - 1/N)
hist(pi.save - 1/2)
hist(pi.save - cfffn(dbh))
hist(pi.save - cdffn(dbh))
hist(pi.save - cdffn(dbh)); abline(v = 0)
hist(pi.save - cdffn(dbh)); abline(v = 0, lty = 2)
hist(pi.save - cdffn(dbh)); abline(v = 0, lwd = 2)
hist(pi.save - cdffn(dbh)); abline(v = 0, lwd = 4)
hist(pi.save - cdffn(dbh)); abline(v = 0, lwd = 8)
hist(pi.save - 1/2 * cdffn(dbh)); abline(v = 0, lwd = 8)
hist(pi.save - cdffn(dbh)); abline(v = 0, lwd = 8)
hist(pi.save - cdffn(dbh) - 1/N); abline(v = 0, lwd = 8)
hist(pi.save - cdffn(dbh) - n/N); abline(v = 0, lwd = 8)
hist(pi.save - cdffn(dbh) - 1/N); abline(v = 0, lwd = 8)
hist(pi.save - cdffn(dbh) - 10/N); abline(v = 0, lwd = 8)
hist(pi.save - cdffn(dbh) - 3/N); abline(v = 0, lwd = 8)
hist(pi.save - cdffn(dbh) - 1/N); abline(v = 0, lwd = 8)
N
hist(pi.save - cdffn(dbh)); abline(v = 0, lwd = 8)
min(pi.save - cdffn(dbh))
max(pi.save - cdffn(dbh))
10/N
1/N
iter <- 10000
est.mn.dbh <- vector(length = iter)
est.var.dbh <- vector(length = iter)
est.mn.bio <- vector(length = iter)
est.var.bio <- vector(length = iter)
bio.fit <- vector(mode = 'list', length = iter)
bio.fit.weight <- vector(mode = 'list', length = iter)
bio.fit.srs <- vector(mode = 'list', length = iter)
pi.save <- rep(0, length = N)
n.save <- vector(length = iter)
s2.core <- 1/8 # Sampling error from coring tree
coefs <- matrix(nrow = iter, ncol = 2)
est.mn.dbh <- vector(length = iter)
est.var.dbh <- vector(length = iter)
est.mn.bio <- vector(length = iter)
est.var.bio <- vector(length = iter)
bio.fit <- vector(mode = 'list', length = iter)
bio.fit.weight <- vector(mode = 'list', length = iter)
bio.fit.srs <- vector(mode = 'list', length = iter)
pi.save <- rep(0, length = N)
n.save <- vector(length = iter)
s2.core <- 1/8 # Sampling error from coring tree
coefs <- matrix(nrow = iter, ncol = 2)
iter <- 10000
est.mn.dbh <- vector(length = iter)
est.var.dbh <- vector(length = iter)
est.mn.bio <- vector(length = iter)
est.var.bio <- vector(length = iter)
bio.fit <- vector(mode = 'list', length = iter)
bio.fit.weight <- vector(mode = 'list', length = iter)
bio.fit.srs <- vector(mode = 'list', length = iter)
pi.save <- rep(0, length = N)
n.save <- vector(length = iter)
s2.core <- 1/8 # Sampling error from coring tree
coefs <- matrix(nrow = iter, ncol = 2)
for(i in 1:iter){
if(i %% 100 == 0){
cat(i, ' ')
}
p <- vector(length = N)
samp.srs <- sample(1:N, n) #SRS sampling for comparison
samp <- sample(1:N)
dbh.samp <- dbh[samp]
bio.samp <- bio[samp]
for(k in 1:N){
x <- dbh.samp[1:k]
fn <- ecdf(x)
p[k] <- fn(x)[k]
}
#	p <- p * 2 * n / N #potential sample size adjustment
samples <- rbinom(N, 1, p)
dbh.pps <- dbh.samp[which(samples == 1)]
error <- rnorm(N, 0, s2.core)
bio.pps <- (bio.samp*exp(error))[which(samples == 1)] #exponential error due to measurement error sampling the cores, not sampling design
n.save[i] <- sum(samples)
probs <- p[which(samples == 1)]
p[samp] <- p
pi.save <- pi.save + 1 / iter * p
est.mn.dbh[i] <- 1 / N * sum(dbh.pps / probs) # check these
est.var.dbh[i] <- (1 / N) * var(dbh.pps / probs)
est.mn.bio[i] <- 1 / N * sum(bio.pps / probs) # check these
est.var.bio[i] <- (1 / N) * var(bio.pps / probs)
model.pps <- lm(log(bio.pps) ~ log(dbh.pps))
coefs[i, ] <- model.pps$coef
bio.fit[[i]] <- exp(model.pps$coef[1]) * dbh^model.pps$coef[2]
model.srs <- lm(log((bio*exp(error))[samp.srs]) ~ log(dbh[samp.srs]))
bio.fit.srs[[i]] <- exp(model.srs$coef[1]) * dbh^model.srs$coef[2]
model.pps.weight <- lm(log(bio.pps) ~ log(dbh.pps), weights = 1 / fn(dbh.pps))
bio.fit.weight[[i]] <- exp(model.pps.weight$coef[1]) * dbh^model.pps.weight$coef[2]
}
#load("pps.test.RData")
apply(coefs, 2, mean) ## Looks pretty unbiased to me
c(log(a), b)
hist(pi.save - cdffn(dbh)); abline(v = 0, lwd = 8)
N
mean(pi.save - cdffn(dbh))
1,3/4,1,1,3/4,2/3,3/4,1,1,1,2/3,3/4,1,1,1,1,1,1,3/4,2/3,3/4,2/3,1/2,1/2), nrow = 3)
1, 3/4, 1, 1, 3/4, 2/3, 3/4, 1, 1, 1, 2/3, 3/4, 1, 1, 1, 1, 1, 1, 3/4, 2/3, 3/4, 2/3, 1/2, 1/2), nrow = 3)
test <- matrix(c(1, 1, 1, 1, 1, 1, 1/2, 1/2, 1/3, 1/4, 1/4, 1/3, 1/2, 1/2, 1/3, 1/4, 1/3, 1/4, 1/2, 1/2, 1/3, 1/4, 1/3, 1/4,
1, 1, 2/3, 1/2, 2/3, 1/2, 1, 1, 1, 1, 1, 1, 2/3, 1/2, 1/2, 1/2, 1/2, 1/3, 2/3, 1/2, 1/2, 1/2, 1/2, 1/3,
1, 3/4, 1, 1, 3/4, 2/3, 3/4, 1, 1, 1, 2/3, 3/4, 1, 1, 1, 1, 1, 1, 3/4, 2/3, 3/4, 2/3, 1/2, 1/2), nrow = 3)
test
rsum(test)
apply(test, 1, sum)
apply(test, 2, sum)
apply(test, 1, sum)
1, 3/4, 1, 1, 3/4, 2/3, 3/4, 1, 1, 1, 2/3, 3/4, 1, 1, 1, 1, 1, 1, 3/4, 2/3, 3/4, 2/3, 1/2, 1/2), byrow = TRUE, nrow = 3)
test <- matrix(c(1, 1, 1, 1, 1, 1, 1/2, 1/2, 1/3, 1/4, 1/4, 1/3, 1/2, 1/2, 1/3, 1/4, 1/3, 1/4, 1/2, 1/2, 1/3, 1/4, 1/3, 1/4,
1, 1, 2/3, 1/2, 2/3, 1/2, 1, 1, 1, 1, 1, 1, 2/3, 1/2, 1/2, 1/2, 1/2, 1/3, 2/3, 1/2, 1/2, 1/2, 1/2, 1/3,
1, 3/4, 1, 1, 3/4, 2/3, 3/4, 1, 1, 1, 2/3, 3/4, 1, 1, 1, 1, 1, 1, 3/4, 2/3, 3/4, 2/3, 1/2, 1/2), byrow = TRUE, nrow = 3)
apply(test, 1, sum)
apply(test, 1, sum)/24
as.fractions(apply(test, 1, sum)/24)
library(MASS)
as.fractions(apply(test, 1, sum)/24)
144/48
75/144
25/48
144/4
75-36
98-72
144/36
36/4
install.packages("knitr")
=======
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
p[i, k] <- fn(x)[k]
}
}
N <- 4
perm.mat <- rbind(1:N, allPerms(N))
pi <- matrix(nrow = dim(perm.mat)[1], ncol = dim(perm.mat)[2])
for(i in 1:dim(perm.mat)[1]){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, k] <- fn(x)[k]
}
}
pi
apply(pi, 2, mean)
perm.mat
pi[i, ][perm.mat[i,]]
library(permute)
N <- 4
perm.mat <- rbind(1:N, allPerms(N))
pi <- matrix(nrow = dim(perm.mat)[1], ncol = dim(perm.mat)[2])
for(i in 1:dim(perm.mat)[1]){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, k] <- fn(x)[k]
}
pi[i,] <- pi[i, ][perm.mat[i,]]
}
apply(pi, 2, mean)
perm.mat[i,]
pi[i, ]
pi[i, ][perm.mat[i,]]
i=1
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, k] <- fn(x)[k]
}
perm.mat[i,]
pi[i, ]
pi[i,] <- pi[i, ][perm.mat[i,]]
pi[1,]
i=2
perm.mat[i,]]
perm.mat[i,]
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, k] <- fn(x)[k]
}
pi[i, ]
pi[i, ][perm.mat[i,]]
pi[i,] <- pi[i, ][perm.mat[i,]]
i=3
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, k] <- fn(x)[k]
}
pi[i, ]
perm.mat[i,]
pi[i, ][perm.mat[i,]]
N <- 4
perm.mat <- rbind(1:N, allPerms(N))
pi <- matrix(nrow = dim(perm.mat)[1], ncol = dim(perm.mat)[2])
for(i in 1:dim(perm.mat)[1]){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, k] <- fn(x)[k]
}
pi[i,] <- pi[i, ][perm.mat[i,]]
}
pi
i=23
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, k] <- fn(x)[k]
}
perm.mat[i,]
pi[i, ]
pi[i, ][perm.mat[i,]]
perm.mat[i,k]
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
pi[23,]
N <- 4
perm.mat <- rbind(1:N, allPerms(N))
pi <- matrix(nrow = dim(perm.mat)[1], ncol = dim(perm.mat)[2])
for(i in 1:dim(perm.mat)[1]){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
#	pi[i,] <- pi[i, ][perm.mat[i,]]
}
pi
apply(pi, 2, mean)
75/144
98/144
121/144
N <- 100
perm.mat <- rbind(1:N, allPerms(N))
?maxperm
perm.mat <- rbind(1:N, allPerms(N, maxperm=9999))
?allPerms
observed = FALSE)
h <- how(within = Within(), plots = Plots(), blocks = NULL,
nperm = 199, complete = FALSE, maxperm = 9999,
minperm = 99, all.perms = NULL, make = TRUE,
observed = FALSE)
h <- how(within = Within(), plots = Plots(), blocks = NULL,
nperm = 199, complete = FALSE, maxperm = 9999,
minperm = 99, all.perms = NULL, make = TRUE,
observed = FALSE)
perm.mat <- rbind(1:N, allPerms(N))
getMaxperm(control)
?getMaxperm
N <- 10
perm.mat <- rbind(1:N, allPerms(N))
N <- 8
perm.mat <- rbind(1:N, allPerms(N))
N <- 6
perm.mat <- rbind(1:N, allPerms(N))
pi <- matrix(nrow = dim(perm.mat)[1], ncol = dim(perm.mat)[2])
for(i in 1:dim(perm.mat)[1]){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
#	pi[i,] <- pi[i, ][perm.mat[i,]]
}
apply(pi, 2, mean)
pi
N <- 7
perm.mat <- rbind(1:N, allPerms(N))
pi <- matrix(nrow = dim(perm.mat)[1], ncol = dim(perm.mat)[2])
for(i in 1:dim(perm.mat)[1]){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
#	pi[i,] <- pi[i, ][perm.mat[i,]]
}
apply(pi, 2, mean)
dim(pi)
N <- 8
perm.mat <- rbind(1:N, allPerms(N))
ctrl <- how(maxperm = 100000)
perm.mat <- rbind(1:N, allPerms(N, control = ctrl))
pi <- matrix(nrow = dim(perm.mat)[1], ncol = dim(perm.mat)[2])
for(i in 1:dim(perm.mat)[1]){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
#	pi[i,] <- pi[i, ][perm.mat[i,]]
}
apply(pi, 2, mean)
wrapper <- function(i){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
#	pi[i,] <- pi[i, ][perm.mat[i,]]
}
sfExportAll()
library(snowfall)
sfExportAll()
library(parallel)
cps <- detectCores()
SfInit(parallel = TRUE, cpus = cps)
sfInit(parallel = TRUE, cpus = cps)
sfExportAll()
pi.test <- sfSapply(1:dim(perm.mat)[2], wrapper)
pi.test
N <- 2
perm.mat <- rbind(1:N, allPerms(N, control = ctrl))
pi <- matrix(nrow = dim(perm.mat)[1], ncol = dim(perm.mat)[2])
for(i in 1:dim(perm.mat)[1]){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
#	pi[i,] <- pi[i, ][perm.mat[i,]]
}
apply(pi, 2, mean)
wrapper <- function(i){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
pi[i, ]
#	pi[i,] <- pi[i, ][perm.mat[i,]]
}
library(snowfall)
library(parallel)
cps <- detectCores()
sfInit(parallel = TRUE, cpus = cps)
sfExportAll()
pi.test <- sfSapply(1:dim(perm.mat)[2], wrapper)
pi.test
pi <- matrix(nrow = dim(perm.mat)[1], ncol = dim(perm.mat)[2])
for(i in 1:dim(perm.mat)[1]){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
#	pi[i,] <- pi[i, ][perm.mat[i,]]
}
pi
pi.test <- sfSapply(1:dim(perm.mat)[1], wrapper)
pi.test
wrapper <- function(i){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
return(pi[i, ])
#	pi[i,] <- pi[i, ][perm.mat[i,]]
}
library(snowfall)
library(parallel)
cps <- detectCores()
sfInit(parallel = TRUE, cpus = cps)
sfExportAll()
pi.test <- sfSapply(1:dim(perm.mat)[1], wrapper)
pi.test
N <- 3
perm.mat <- rbind(1:N, allPerms(N, control = ctrl))
wrapper <- function(i){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
return(pi[i, ])
#	pi[i,] <- pi[i, ][perm.mat[i,]]
}
library(snowfall)
library(parallel)
sfExportAll()
pi.test <- sfSapply(1:dim(perm.mat)[1], wrapper)
pi.test
pi.test <- sfSapply(1:dim(perm.mat)[2], wrapper)
pi.test
dim(perm.mat)[2]
dim(perm.mat)[1]
pi <- matrix(nrow = dim(perm.mat)[1], ncol = dim(perm.mat)[2])
sfExportAll()
pi.test <- sfSapply(1:dim(perm.mat)[1], wrapper)
pi.test
wrapper <- function(i){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
pi[i, ]
#	pi[i,] <- pi[i, ][perm.mat[i,]]
}
pi <- matrix(nrow = dim(perm.mat)[1], ncol = dim(perm.mat)[2])
sfExportAll()
pi.test <- sfSapply(1:dim(perm.mat)[1], wrapper)
pi.test
library(permute)
ctrl <- how(maxperm = 100000)
N <- 3
perm.mat <- rbind(1:N, allPerms(N, control = ctrl))
pi <- matrix(nrow = dim(perm.mat)[1], ncol = dim(perm.mat)[2])
for(i in 1:dim(perm.mat)[1]){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
#	pi[i,] <- pi[i, ][perm.mat[i,]]
}
apply(pi, 2, mean)
N <- 10
perm.mat <- rbind(1:N, allPerms(N, control = ctrl))
ctrl <- how(maxperm = 10000000)
N <- 10
perm.mat <- rbind(1:N, allPerms(N, control = ctrl))
pi <- matrix(nrow = dim(perm.mat)[1], ncol = dim(perm.mat)[2])
for(i in 1:dim(perm.mat)[1]){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
#	pi[i,] <- pi[i, ][perm.mat[i,]]
}
N <- 5
perm.mat <- rbind(1:N, allPerms(N, control = ctrl))
pi <- matrix(nrow = dim(perm.mat)[1], ncol = dim(perm.mat)[2])
for(i in 1:dim(perm.mat)[1]){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
#	pi[i,] <- pi[i, ][perm.mat[i,]]
}
apply(pi, 2, mean)
library(MASS)
as.fractions(apply(pi, 2, mean))
137*4
237*2
237*3
437*2
548/1200
137*4
237*3
437*2
as.fractions(apply(pi, 2, mean))
## N = 5, denominator of 1200
137*4
237*3
437*2
1/5
1200/5
240/1200
960/1200
548-240
137*4 - 240
237*3 - 240 * 2
437*2 - 240 * 3
1037 - 240 * 4
N <- 6
perm.mat <- rbind(1:N, allPerms(N, control = ctrl))
pi <- matrix(nrow = dim(perm.mat)[1], ncol = dim(perm.mat)[2])
for(i in 1:dim(perm.mat)[1]){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
#	pi[i,] <- pi[i, ][perm.mat[i,]]
}
apply(pi, 2, mean)
as.fractions(apply(pi, 2, mean))
49*5
79*4
129*3
229*2
145/600
1/4
library(permute)
library(MASS)
ctrl <- how(maxperm = 10000000)
N <- 6
perm.mat <- rbind(1:N, allPerms(N, control = ctrl))
pi <- matrix(nrow = dim(perm.mat)[1], ncol = dim(perm.mat)[2])
for(i in 1:dim(perm.mat)[1]){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
#	pi[i,] <- pi[i, ][perm.mat[i,]]
}
apply(pi, 2, mean)
as.fractions(apply(pi, 2, mean))
N <- 7
perm.mat <- rbind(1:N, allPerms(N, control = ctrl))
pi <- matrix(nrow = dim(perm.mat)[1], ncol = dim(perm.mat)[2])
for(i in 1:dim(perm.mat)[1]){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
#	pi[i,] <- pi[i, ][perm.mat[i,]]
}
apply(pi, 2, mean)
as.fractions(apply(pi, 2, mean))
5880/980
1176*5
1960*3
363*6
559*5
300*4
1343*3
2323*2
5880/7
363*6
559*5
300*4
1343*3
2323*2
as.fractions(apply(pi, 2, mean))
300*8
5880/517
5880/1176
1343*3
2323*2
363*6 - 840
840*2
559*5 - 840*2
840*3
300*4 - 840*3
840*4
1343*3 - 840*4
840*5
2323*2 - 840*5
5263 - 840*6
669+223
892+223
892/5880 + 300/517
as.fraction(892/5880 + 300/517)
as.fractions(892/5880 + 300/517)
8550/832
is.prime(517)
517*5880
divisors(3039960)
as.fractions(apply(pi, 2, mean))
517/3
517/7
517/5
517/9
517/11
517/3
11*47
5880/11
5880/47
5880*517
## N = 7 denominator of 3039960
363*6*517
559*5*517
## 517 has divisors of 11 and 47
## 5880
300*5880
1343*3*517
2323*2*517
363*6*517
559*5*517
## 517 has divisors of 11 and 47
## 5880
300*5880
1343*3*517
2323*2*517
as.fractions(apply(pi, 2, mean))
1343*3*517
2323*2*517
5263*517
363*6*517 - 840*517
840*517
840*517/3039960
1/7
840*517
363*6*517 - 840*517
691746-434280
363*6*517 - 840*517
363*6*517
840*2*517
559*5 - 840*2*517
559*5*517 - 840*2*517
300*4*517 - 840*3*517
300*5880 - 840*3*517
1343*3*517 - 840*4*517
2323*2*517 - 840*5*517
5263*517 - 840*6*517
840*6*517
840*5*517
840*4*517
840*3*517
840*2*517
factorial(4)
factorial(4)*4
factorial(3)*3
factorial(3)^2
factorial(4)^2
factorial(4)^2/4
factorial(5)^2
14400/1200
factorial(6)^2
518400/600
factorial(7)^2
factorial(7)^2 / 3039960
ctrl <- how(maxperm = 10000000)
N <- 7
perm.mat <- rbind(1:N, allPerms(N, control = ctrl))
pi <- matrix(nrow = dim(perm.mat)[1], ncol = dim(perm.mat)[2])
for(i in 1:dim(perm.mat)[1]){
for(k in 1:dim(perm.mat)[2]){
x <- perm.mat[i, 1:k]
fn <- ecdf(x)
pi[i, perm.mat[i,k]] <- fn(x)[k]
}
#	pi[i,] <- pi[i, ][perm.mat[i,]]
}
apply(pi, 2, mean)
as.fractions(apply(pi, 2, mean))
517*5880
factorial(7)^2
>>>>>>> 603d545dacbba703d902bd1485c6cbbb05ae2a9a
